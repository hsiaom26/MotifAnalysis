{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.5 |Continuum Analytics, Inc.| (default, Jul  5 2016, 14:53:07) [MSC v.1600 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# input \n",
    "familyName = \"eggnog\"\n",
    "generation = \"main\"\n",
    "treeNumber = \"all\"\n",
    "\n",
    "data_directory = \"tracelogs_analysis_simplify/Selected/\"+familyName+\"/\"+generation+\"/\"+ treeNumber + '/' # make sure the last character is '/'\n",
    "in_tag = familyName + \"_0.8\"\n",
    "in_parseFirstPar = True # keep first parameter or not\n",
    "in_window = 1\n",
    "\n",
    "outputPath = \"output/GSA/\" + in_tag + \"-2/\" + data_directory.split('/')[-2] + \"/\" # MIKE: no 'l' at the end. It is ridiculous!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fp_removeDuplicateAPI(featureTrace): # remove duplicate api if continuously occur\n",
    "#     result = []\n",
    "#     lastAPI = \"\"\n",
    "#     for api in featureTrace:\n",
    "#         if lastAPI != api: # find new api\n",
    "#             result.append(api)\n",
    "#             lastAPI = api\n",
    "#     return result\n",
    "\n",
    "# def fp_removeUnwantedAPI(featureTrace): # remove unwanted api\n",
    "#     result = []\n",
    "#     unwanted_api = {'CloseHandle', 'OpenThread', 'RegOpenKey', 'RegCloseKey'}\n",
    "#     frequently_used_lib = {'imm32', 'lpk', 'gdi32', 'kernel32', 'ntdll', 'user32', 'comctl32', 'advapi64'}\n",
    "\n",
    "#     for api in featureTrace:\n",
    "#         API = api.split('#')[0]\n",
    "        \n",
    "#         if API == \"LoadLibrary\": # api is LoadLibrary\n",
    "#             libName = api.split(\"@\")[2]\n",
    "#             if libName not in frequently_used_lib: # found new library, add it into lib_set and result_Hooklog\n",
    "#                 result.append(api)\n",
    "#                 frequently_used_lib.update(libName)\n",
    "                \n",
    "#         elif API not in unwanted_api: # api not unwanted\n",
    "#             result.append(api)\n",
    "            \n",
    "#     return result\n",
    "\n",
    "# def et_removeDuplicateAPI(execTrace):\n",
    "#     result = []\n",
    "#     lastAPI = \"\"\n",
    "#     for trace in execTrace:\n",
    "#         timeStamp = trace[0]\n",
    "#         api = trace[1]\n",
    "#         if lastAPI != api: # find new api\n",
    "#             result.append((timeStamp, api))\n",
    "#             lastAPI = api\n",
    "#     return result\n",
    "\n",
    "# def et_removeUnwantedAPI(execTrace): # remove unwanted api\n",
    "#     result = []\n",
    "#     unwanted_api = {'CloseHandle', 'OpenThread', 'RegOpenKey', 'RegCloseKey'}\n",
    "#     frequently_used_lib = {'imm32', 'lpk', 'gdi32', 'kernel32', 'ntdll', 'user32', 'comctl32', 'advapi64'}\n",
    "\n",
    "#     for trace in execTrace:\n",
    "#         timeStamp = trace[0]\n",
    "#         api = trace[1]\n",
    "        \n",
    "#         API = api.split('#')[0]\n",
    "        \n",
    "#         if API == \"LoadLibrary\": # api is LoadLibrary\n",
    "#             libName = api.split(\"@\")[2]\n",
    "#             if libName not in frequently_used_lib: # found new library, add it into lib_set and result_Hooklog\n",
    "#                 result.append((timeStamp, api))\n",
    "#                 frequently_used_lib.update(libName)\n",
    "                \n",
    "#         elif API not in unwanted_api: # api not unwanted\n",
    "#             result.append((timeStamp, api))\n",
    "            \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1.Get a dict of feature profiles (out: a hkName list, a featureProfile dict)\n",
    "%run FeatureTrace.ipynb\n",
    "FeatTrace = FeatureTrace\n",
    "\n",
    "traceName_li = list(filter(lambda f:f.endswith('.trace.hooklog'), os.listdir(data_directory))) # hooklog Name List\n",
    "\n",
    "fp_dict = dict()\n",
    "execTrace_dict = dict()\n",
    "\n",
    "for f in traceName_li:\n",
    "    featureTrace = FeatTrace(data_directory + f).getTrace_noContainTS()\n",
    "#     featureTrace = fp_removeDuplicateAPI(featureTrace)\n",
    "#     featureTrace = fp_removeUnwantedAPI(featureTrace)\n",
    "    fp_dict[f] = featureTrace\n",
    "    \n",
    "    execTrace = FeatTrace(data_directory + f).getTrace_containTS()\n",
    "#     execTrace = et_removeDuplicateAPI(execTrace)\n",
    "#     execTrace = et_removeUnwantedAPI(execTrace)\n",
    "    execTrace_dict[f] = execTrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "008e76aafe9bd3132293816e6b0ac8e68cea5445c47065e53d7028ddbe375843_3272.trace.hooklog\n"
     ]
    }
   ],
   "source": [
    "# 2.Get a dict of pairwise alignment result \n",
    "# (in: a featureProfile dict; out: alignmentProfile dict, alingmnt baseline)\n",
    "\n",
    "# %run Alignment3.ipynb\n",
    "%run Alignment_Fast3.ipynb\n",
    "\n",
    "BASE = traceName_li[0] # randomly pick a BASE trace log\n",
    "# BASE = \"008e76aafe9bd3132293816e6b0ac8e68cea5445c47065e53d7028ddbe375843_3272.trace.hooklog\" # specified base\n",
    "fpBASE = fp_dict[BASE]\n",
    "print(BASE)\n",
    "align_dict = {hk:pairwise_NW( fpBASE, fp_dict[hk], 2, -1, -3, 1)[2] for hk in traceName_li } # pairwise all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Get matchMatrix, gapSeqList\n",
    "# (in: alignmentProfile dict; out: matchMatrix, gapSeqList)\n",
    "%run StructMatchGap3.ipynb\n",
    "\n",
    "data = structMatchGap(align_dict, BASE)\n",
    "matchMatrix = data[0]\n",
    "gapSeqList = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Get stageMatrix \n",
    "# (in: matchMatrix, gapSeqList; out: stageMatrix)\n",
    "% run StageMatrix.ipynb\n",
    "\n",
    "stageMatrixResult = stageMatrix(matchMatrix, gapSeqList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  5. Get Motif Elements\n",
    "# (in: stageMatrixResult, BASE; out: Motif object)\n",
    "% run Motif.ipynb\n",
    "\n",
    "Motif = Motif(stageMatrixResult, BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  Garbage Code  -->>>  Work around only!   #####\n",
    "###  WJ:  I don't know why do this!?\n",
    "\n",
    "#with open('docs/label_dict-m2t-t2m-2014.pickle', 'rb') as f:\n",
    "#    label_dict = pickle.load(f)[1] #(proc_list,proc_dict,label_list, label_dict)\n",
    "#label_dict = {k[:-len('.trace.hooklog')]:label_dict[k] for k in label_dict}\n",
    "\n",
    "# MIKE: 20170808, I comment it. Need to come back again.\n",
    "label_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: graph has 1006 nodes...layout may take a long time.\n",
      "Warning: graph has 1006 nodes...layout may take a long time.\n",
      "Warning: graph has 1006 nodes...layout may take a long time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.OutputMotiGraph at 0x9ebbeb8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Drawing stages graphs\n",
    "## output into 'outputPath'\n",
    "% run OutputStageBarchart3.ipynb\n",
    "\n",
    "if not os.path.isdir(outputPath): os.makedirs(outputPath)\n",
    "outputStage = OutputStage( stageMatrixResult, outputPath, BASE, Motif ) # output stages graphs\n",
    "OutputMotiGraph(stageMatrixResult, BASE, fp_dict, outputStage, outputPath, Motif, label_dict) # output motif graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Output common motif analysis\n",
    "# output into 'outputPath'\n",
    "% run CommonMotifAnalysis3.ipynb\n",
    "execTrace_dict = fp_dict\n",
    "motiDict = MotiDict(stageMatrixResult, Motif, execTrace_dict, outputStage)\n",
    "comMotif = motiDict.getComMoti()\n",
    "# comResAnalysis = ComResAnalysis(comMotif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.OutputCsv at 0x9ebbcc0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "% run OutputCommonMotif3.ipynb\n",
    "OutputCsv(outputPath, comMotif, stageMatrixResult, Motif, BASE, execTrace_dict, outputStage)\n",
    "# OutputComMotiAnaly(comResAnalysis, outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
