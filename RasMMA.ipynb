{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A implementation of Sequence-Based Behavior Group Clustering Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shorten Name to first 6 charactors\n",
    "def shortenHooklogName(hkName):\n",
    "    hashValue = hkName[0:6]\n",
    "    pid = hkName.split(\"_\")[1].split(\".\")[0]\n",
    "    return hashValue+\"_\"+pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input: two R\n",
    "# output: new RepresentativeR of inputs;\n",
    "def get_Representative(Ri, Rj):\n",
    "    rep1 = list()\n",
    "    rep2 = list()\n",
    "\n",
    "#     print(Ri[0], Rj[0])\n",
    "    for i in range(len(Ri[1])): # get length of R's common motif seqs  (p.s. Ri[0] is clusterName)\n",
    "        rep1 += Ri[1][i][0]\n",
    "    for i in range(len(Rj[1])):\n",
    "        rep2 += Rj[1][i][0]\n",
    "    \n",
    "    repNew = list() \n",
    "    \n",
    "    if(rep1 and rep2):\n",
    "        comMotif_dict = do_globalAlignment(rep1, rep2) # do Alignment\n",
    "        newStartIdx = 0\n",
    "\n",
    "        for m in sorted(comMotif_dict.keys(), key = lambda x : int(x.split('_')[0][1:])): # sorted by stages\n",
    "            cmsList = comMotif_dict[m]\n",
    "            newEndIdx = newStartIdx + len(cmsList[0]) - 1\n",
    "            repNew.append((cmsList[0], newStartIdx, newEndIdx, cmsList[1], cmsList[2]))\n",
    "                      # [CMS, newCMSStartIdx, newCMSEndIdx, oriIdxRange1, oriIdxRange2]\n",
    "            newStartIdx = newEndIdx + 1\n",
    "    rep1.clear()\n",
    "    rep2.clear()\n",
    "    del comMotif_dict\n",
    "    return repNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% run Alignment_Fast3.ipynb\n",
    "% run StructMatchGap3.ipynb\n",
    "% run StageMatrix.ipynb\n",
    "% run Motif.ipynb\n",
    "% run OutputStage.ipynb\n",
    "% run CommonMotifAnalysis_Tmp.ipynb\n",
    "\n",
    "# Doing global alignment and Calculate common motif.\n",
    "# will return a common motif dict\n",
    "def do_globalAlignment(rep1, rep2):\n",
    "    # Aligment\n",
    "    align_dict = dict()\n",
    "    BASE = \"rep1\"\n",
    "    align_dict['rep1'] = pairwise_NW( rep1, rep1, 2, -1, -3, 1)[2]\n",
    "    align_dict['rep2'] = pairwise_NW( rep1, rep2, 2, -1, -3, 1)[2]\n",
    "    \n",
    "    # get 'Match Matrix' and 'Gap List'\n",
    "    matchMatrix, gapSeqList = structMatchGap(align_dict, BASE)\n",
    "    stageMatrixResult = stageMatrix(matchMatrix, gapSeqList)\n",
    "    Motif_Obj = Motif(stageMatrixResult, BASE)\n",
    "    outputStage = OutputStage(stageMatrixResult, None, BASE, Motif_Obj)\n",
    "    \n",
    "    executionTrace_dict = {\"rep1\":rep1, \"rep2\":rep2}\n",
    "    \n",
    "    commonMotif = CommonMotif(stageMatrixResult, Motif_Obj, executionTrace_dict, outputStage)\n",
    "    \n",
    "    # comMotifdict= {'s<stage>_<motif>': [CMS], oriIdxRange1, oriIdxRange2},\n",
    "    comMotif_dict = commonMotif.getComMotifDict()  \n",
    "    return comMotif_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% run FeatureHooklog3.ipynb\n",
    "#******************** the output toMergeCandidate_Dict have to change to set\n",
    "\n",
    "# initialize all hooklogs as \"to merge candidates clusters\"\n",
    "def initialCandidateDict(data_directory):\n",
    "    \n",
    "#     toMergeCandidate_List = list()\n",
    "    toMergeCandidate_Dict = dict()\n",
    "    \n",
    "    # get feature hooklogs\n",
    "    Hooklog = FeatureHooklog3\n",
    "    hkName_list = list(filter(lambda f:f.endswith('.trace.hooklog'), os.listdir(data_directory))) # hooklog Name List\n",
    "    hk_count = 0\n",
    "    for hkName in hkName_list:\n",
    "        featureHooklog = Hooklog(data_directory + hkName, 1).getHkli_noContainTS()\n",
    "#         featureHooklog = [line.rstrip('\\n') for line in open(data_directory + hkName)]\n",
    "        clusterName = \"G\"+str(hk_count)\n",
    "        # R = tuple( clusterName, list(  tuple(featureHooklog, fhStartIdx, fhEndIdx) ) ), the representative of cluster.\n",
    "        R = (clusterName, [(featureHooklog, 0, len(featureHooklog)-1)] )\n",
    "        clusterMembers = set()\n",
    "        hkName = shortenHooklogName(hkName)\n",
    "        clusterMembers.add(hkName)\n",
    "        \n",
    "        toMergeCandidate_Dict[hk_count] = (R, clusterMembers)\n",
    "        \n",
    "        hk_count+=1\n",
    "        \n",
    "    print(\"-- Finish Initializing --\")\n",
    "    return toMergeCandidate_Dict\n",
    "#     return toMergeCandidateSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return a dictionary that contains the initializing informations\n",
    "#\n",
    "# initialDict = {clusterName : (originalName, initialLength)}\n",
    "\n",
    "def getInitialDict(toMergeCandidateDict):\n",
    "    initialDict = dict()\n",
    "    for key, value in toMergeCandidateDict.items():\n",
    "        clusterName = value[0][0]\n",
    "        initialLen = value[0][1][0][2] + 1\n",
    "        originalName = value[1].pop()\n",
    "        initialDict[clusterName] = (originalName, initialLen)\n",
    "        value[1].add(originalName)\n",
    "    return initialDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return a dict that contains only original name\n",
    "# nameDict = {clusterName: original name}\n",
    "\n",
    "def getInitialNameDict(initialDict):\n",
    "    nameDict = dict()\n",
    "    for key, value in initialDict.items():\n",
    "        name = value[0]\n",
    "        nameDict[key] = name\n",
    "    return nameDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "# compute score of Rnew\n",
    "# the score calculate method is the length ratio of new to origin one\n",
    "def compute_Score(Ri, Rj, Rnew):\n",
    "    \n",
    "    if(Rnew[1]):\n",
    "        L_Ri = functools.reduce(lambda x,y:x+y, [len(i[0]) for i in Ri[1]])\n",
    "        L_Rj = functools.reduce(lambda x,y:x+y, [len(j[0]) for j in Rj[1]])\n",
    "    \n",
    "        Lorg = max(L_Ri, L_Rj)\n",
    "        Lnew = functools.reduce(lambda x,y:x+y, [len(n[0]) for n in Rnew[1]]) \n",
    "        return float(Lnew)/Lorg\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get score list of toMergeCandidateDict(single iteration) from highest to lowest\n",
    "\n",
    "def findMergeCandidateScoreList(toMergeCandidateDict, generatedSeqNum):\n",
    "    scoreList = list()\n",
    "    dictKeys = list(toMergeCandidateDict.keys())\n",
    "    \n",
    "    sensitiveAPIs = {\"CreateProcessInternal\", \"OpenProcess\", \"WinExec\", \"CreateThread\", \"OpenThread\", \"CreateRemoteThread\",\n",
    "                     \"CopyFile\", \"CreateFile\", \"WriteFile\", \"ReadFile\", \"DeleteFile\", \"RegCreateKey\", \"RegSetValue\",\n",
    "                     \"InternetOpen\", \"InternetConnect\", \"HttpSendRequest\", \"WinHttpOpen\", \"WinHttpSendRequest\", \"WinHttpWriteData\", \"WinHttpCreateUrl\"}\n",
    "    \n",
    "    for i in range(len(dictKeys)):\n",
    "        for j in range(i+1, len(dictKeys)):\n",
    "            \n",
    "            # toMergeCandidateDict[i][1] is memberSet\n",
    "            Ri = toMergeCandidateDict[ dictKeys[i] ][0] # Ri is a tuple like (('G0', [[['A#A', 'C#C'], 0, 1, (0, 1), (1, 2)]]))\n",
    "            Rj = toMergeCandidateDict[ dictKeys[j] ][0]\n",
    "            \n",
    "            print(toMergeCandidateDict[ dictKeys[i] ][1], toMergeCandidateDict[ dictKeys[j] ][1])\n",
    "            \n",
    "            # create Rnew = (clusterName , repNew)\n",
    "            repNew = get_Representative(Ri, Rj)\n",
    "            clusterTempName = \"G\" + str(generatedSeqNum)\n",
    "            Rnew = (clusterTempName , repNew)\n",
    "            couldBeMergedFlag = True\n",
    "            \n",
    "#             couldBeMergedFlag =False\n",
    "#             RnewSequenceLen = 0\n",
    "#             for motifInfo in Rnew[1]:\n",
    "#                 motifLen = len(motifInfo[0])\n",
    "                \n",
    "#                 # Check if any API in rep contains sensitive API\n",
    "#                 for motif in motifInfo[0]:\n",
    "#                     if motif.split('#')[0] in sensitiveAPIs:\n",
    "#                         couldBeMergedFlag = True\n",
    "#                         break\n",
    "                \n",
    "#                 # if no any sensitive API, check sequence length of rep bigger than 26\n",
    "#                 if(couldBeMergedFlag == False):\n",
    "#                     RnewSequenceLen += motifLen\n",
    "#                     if(RnewSequenceLen > 26):\n",
    "#                         couldBeMergedFlag = True\n",
    "#                         break\n",
    "                \n",
    "            # if the rep could be merged, then put into scoreList.\n",
    "            if( couldBeMergedFlag ):\n",
    "            \n",
    "                # compute merge score of Rnew\n",
    "                score = compute_Score(Ri, Rj, Rnew)\n",
    "                Ri_name = Ri[0]\n",
    "                Rj_name = Rj[0]\n",
    "                scoreList.append((score, Rnew, Ri_name, Rj_name))\n",
    "                \n",
    "#             else:\n",
    "#                 print(\"Rep Sequence Length smaller than 26! Length: \", RnewSequenceLen)\n",
    "\n",
    "    if(len(scoreList) > 0):\n",
    "        scoreList.sort(key=lambda tup:tup[0], reverse=True) # sorting by score (from biggest to smallest) \n",
    "    else:\n",
    "        print(\"No common motif\")\n",
    "    \n",
    "    return scoreList # list = [(score, Rnew, Ri_name, Rj_name), (score, Rnew, Ri_name, Rj_name), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkExactlySameCandidates(scoreList):\n",
    "    globalPoolDict = dict() # a dict contains many sets.  dict = {index0: memberSet, 1: memberSet, 2:...}\n",
    "    newScoreList = list() # list = [(score, R, memberSet), (score, R, memberSet), ...]\n",
    "    scoreListIdx = 0\n",
    "    for rank in scoreList:\n",
    "        score = rank[0]\n",
    "       \n",
    "        if(score == 1.0):\n",
    "            \n",
    "            Ri_name = rank[2]\n",
    "            Rj_name = rank[3]\n",
    "            \n",
    "            duplicate = False\n",
    "            for key, memberSet in globalPoolDict.items():\n",
    "                if(Ri_name in memberSet) or (Rj_name in memberSet):\n",
    "                    memberSet.add(Ri_name)\n",
    "                    memberSet.add(Rj_name)\n",
    "                    \n",
    "                    # update newScoreList 'memberSet' element\n",
    "                    newScoreList[key] = (newScoreList[key][0], newScoreList[key][1], memberSet)\n",
    "                    duplicate = True\n",
    "                    \n",
    "            # Find new independent pair, add into newScoreList and create new dict key\n",
    "            if(duplicate is False):\n",
    "                memberSet = set()\n",
    "                memberSet.add(Ri_name)\n",
    "                memberSet.add(Rj_name)\n",
    "                globalPoolDict[scoreListIdx] = memberSet\n",
    "                \n",
    "                Rnew = rank[1]\n",
    "                newScoreList.append((score, Rnew, memberSet))\n",
    "                scoreListIdx += 1\n",
    "        else:\n",
    "            Rnew = rank[1]\n",
    "            Ri_name = rank[2]\n",
    "            Rj_name = rank[3]\n",
    "            memberSet = set()\n",
    "            memberSet.add(Ri_name)\n",
    "            memberSet.add(Rj_name)\n",
    "            newScoreList.append((score, Rnew, memberSet))\n",
    "            scoreListIdx += 1\n",
    "            \n",
    "    return newScoreList # list = [(score, R, memberSet), (score, R, memberSet), ...]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # unit test\n",
    "# item1 = (1.0, (\"G0\", \"[['A#A', 'B#B','B#B', 'C#C','D#D'], 0, 2]\"), \"a.txt\", \"b.txt\")\n",
    "# item2 = (1.0, (\"G1\", \"[['A#A', 'B#B','B#B', 'C#C','D#D'], 0, 2]\"), \"a.txt\", \"c.txt\")\n",
    "# item3 = (1.0, (\"G2\", \"[['A#A', 'B#B','B#B', 'C#C','D#D'], 0, 2]\"), \"b.txt\", \"c.txt\")\n",
    "# item4 = (1.0, (\"G3\", \"[['A#A', 'B#B','B#B', 'C#C','D#D'], 0, 2]\"), \"c.txt\", \"d.txt\")\n",
    "# item5 = (1.0, (\"G4\", \"[['E#A', 'F#B'], 0, 2]\"), \"e.txt\", \"f.txt\")\n",
    "# item6 = (0.8, (\"G5\", \"[['X#A', 'Y#B'], 0, 2]\"), \"x.txt\", \"y.txt\")\n",
    "\n",
    "# scoreList = [item1, item2, item3, item4, item5, item6]\n",
    "\n",
    "# newScoreList = checkExactlySameCandidates(scoreList)\n",
    "# print(newScoreList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add Rnew into toMergeCandidateDict and remove member of Rnew from candidates.\n",
    "\n",
    "def mergeCandidateClusters_new(toMergeCandidateDict, intermediatePoolDict, scoreList, generatedSeqNum, initialDict, definedThreshold):\n",
    "    initialNameDict = getInitialNameDict(initialDict) # get original name for reference in output.\n",
    "    \n",
    "    currentMergedSet = set()\n",
    "    for rank in scoreList:\n",
    "        score = rank[0]\n",
    "        memberSet = rank[2] # memberSet of highest score\n",
    "\n",
    "        # the minmum score this round is smaller than threshold\n",
    "        if(score < definedThreshold):\n",
    "            break\n",
    "        \n",
    "        exclusiveness = False\n",
    "        \n",
    "        # check exclusiveness\n",
    "        for member in memberSet:\n",
    "            if(member in currentMergedSet):\n",
    "                exclusiveness = True\n",
    "                break\n",
    "                \n",
    "        if(not exclusiveness):\n",
    "            clusterMembers = set() # create cluster member set with original Name\n",
    "            for member in memberSet:\n",
    "                nameOfMember = int(member.split('G')[1])\n",
    "                del toMergeCandidateDict[nameOfMember]\n",
    "                \n",
    "                if member in initialNameDict:\n",
    "                    clusterMembers.add(initialNameDict[member])\n",
    "                else:\n",
    "                    clusterMembers.add(member)\n",
    "                    \n",
    "                # Mark elements are merged\n",
    "                currentMergedSet.add(member) # update currentMergedSet\n",
    "            \n",
    "            Rnew = rank[1][1] # representative without old clusterName (i.e., rank[1] = (Name, Rep.))\n",
    "            newName = \"G\" + str(generatedSeqNum)\n",
    "            new_Cluster = (newName, Rnew)\n",
    "            \n",
    "            toMergeCandidateDict[generatedSeqNum] = (new_Cluster, clusterMembers)\n",
    "            intermediatePoolDict[generatedSeqNum] = (score, new_Cluster, clusterMembers) # (score, newCluster, members)\n",
    "            generatedSeqNum += 1\n",
    "        \n",
    "    return toMergeCandidateDict, intermediatePoolDict, generatedSeqNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add Rnew into toMergeCandidateDict and remove member of Rnew from candidates.\n",
    "\n",
    "def mergeCandidateClusters(toMergeCandidateDict, intermediatePoolDict, scoreList, generatedSeqNum, initialDict):\n",
    "    currentMergedSet = set()\n",
    "    \n",
    "    initialNameDict = getInitialNameDict(initialDict)\n",
    "    \n",
    "    for rank in scoreList:\n",
    "        Ri_name = rank[2] # member1 of highest score\n",
    "        Rj_name = rank[3] # member2 of highest score\n",
    "        \n",
    "        # check exclusiveness that candidate have been merged in current scoreList.\n",
    "        # if both two element haven't been processed then create new cluster.\n",
    "        if((Ri_name not in currentMergedSet) and (Rj_name not in currentMergedSet)):\n",
    "            # remove candidates in @toMergeCandidateDict\n",
    "            keyOfRi = int(Ri_name.split('G')[1])\n",
    "            keyOfRj = int(Rj_name.split('G')[1])\n",
    "            del toMergeCandidateDict[keyOfRi], toMergeCandidateDict[keyOfRj]\n",
    "\n",
    "            Rnew = rank[1] # get representative of highest score\n",
    "            newName = \"G\" + str(generatedSeqNum) # update clusterName\n",
    "        \n",
    "            new_Cluster = (newName, Rnew[1])\n",
    "\n",
    "            clusterMembers = set() # create cluster member set\n",
    "            if Ri_name in initialNameDict:\n",
    "                clusterMembers.add(initialNameDict[Ri_name])\n",
    "            else:\n",
    "                clusterMembers.add(Ri_name)\n",
    "            \n",
    "            \n",
    "            if Rj_name in initialNameDict:\n",
    "                clusterMembers.add(initialNameDict[Rj_name])\n",
    "            else:\n",
    "                clusterMembers.add(Rj_name)\n",
    "            \n",
    "            \n",
    "            toMergeCandidateDict[generatedSeqNum] = (new_Cluster, clusterMembers)\n",
    "            intermediatePoolDict[generatedSeqNum] = (rank[0], new_Cluster, clusterMembers) # (score, newCluster, members)\n",
    "\n",
    "            generatedSeqNum += 1\n",
    "        \n",
    "        # Mark elements are merged\n",
    "        currentMergedSet.add(Ri_name) # update currentMergedSet\n",
    "        currentMergedSet.add(Rj_name)\n",
    "        \n",
    "    return toMergeCandidateDict, intermediatePoolDict, generatedSeqNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Main Function of SBBGCA ###\n",
    "\n",
    "import pickle\n",
    "\n",
    "def do_SBBGCA_clustering(data_directory, tag, outputPath, thresholdValue):\n",
    "#     testDict = {0: (('G0', [[['A#A', 'B#B','B#B', 'C#C','D#D'], 0, 2]]),{\"a.trace.hooklog\"}),\n",
    "#                 1:(('G1', [[['A#A','B#B','C#C','D#D'], 0, 2]]),{\"b.trace.hooklog\"}),\n",
    "#                    2:(('G2', [[['F#F','C#C','D#D', 'G#G'], 0, 2]]),{\"c.trace.hooklog\"}),\n",
    "#                       3:(('G3', [[['Q#Q','C#C','D#D','G#G'], 0, 2]]),{\"d.trace.hooklog\"}),\n",
    "#                            4:(('G4', [[['A#A'], 0, 2]]),{\"e.trace.hooklog\"})}\n",
    "    intermediatePool = dict()\n",
    "    roundInfos = dict()\n",
    "    residual = None # used to save residual candidate when algorithm stop.\n",
    "#     toMergeCandidateDict = testDict\n",
    "    toMergeCandidateDict = initialCandidateDict(data_directory) # initialize @toMergeCandidateDict\n",
    "\n",
    "    # initialDict = {clusterName : (originalName, initialLength)}\n",
    "    initialDict = getInitialDict(toMergeCandidateDict)\n",
    "    \n",
    "    roundProduct = list()\n",
    "    for key, value in initialDict.items():\n",
    "        roundProduct.append(key)\n",
    "    roundInfos[0] = roundProduct # record product in round 0 (i.e., initialization)\n",
    "    \n",
    "    generatedSeqNum = len(toMergeCandidateDict) # counter after initialize. Used to naming clusters.\n",
    "\n",
    "    print(\"-- Start Clustering --\")\n",
    "    print(\"Threshold set =\", thresholdValue)\n",
    "    roundCounter = 1\n",
    "    \n",
    "    while(1):\n",
    "        if(len(toMergeCandidateDict) == 1):\n",
    "            residual = toMergeCandidateDict # output residual candidates.\n",
    "            break\n",
    "\n",
    "        # calculate scoreList in candidate clusters\n",
    "        scoreList = findMergeCandidateScoreList(toMergeCandidateDict, generatedSeqNum)\n",
    "        \n",
    "        # check and merge exactly the same candidates before merge clusters\n",
    "        scoreList = checkExactlySameCandidates(scoreList)\n",
    "        \n",
    "        # generated Clusters in This Round:\n",
    "        nameIdxStart = generatedSeqNum\n",
    "        \n",
    "        toMergeCandidateDict, intermediatePool, generatedSeqNum = mergeCandidateClusters_new(\n",
    "            toMergeCandidateDict, intermediatePool, scoreList, generatedSeqNum, initialDict, thresholdValue)\n",
    "        \n",
    "        # check if algorithm should stop when merge score under threshold\n",
    "        # if a score smaller than threshold, then it will break out when merging.\n",
    "        # Hense, if the 'generatedSeqNum' equals than 'nameIdxStart', means that no any new generated cluster.\n",
    "        # (if occurr a new cluster, generatedSeqNum will add one.)\n",
    "        if(generatedSeqNum == nameIdxStart):\n",
    "            residual = toMergeCandidateDict # output residual candidates.\n",
    "            break # end algorithm\n",
    "        \n",
    "        nameIdxEnd = generatedSeqNum\n",
    "        \n",
    "        # Record clusters generated in this round\n",
    "        for idx in range(nameIdxStart, nameIdxEnd):\n",
    "            if roundInfos.get(roundCounter) is None:\n",
    "                roundProduct = list()\n",
    "                roundProduct.append(intermediatePool[idx][1][0])\n",
    "                roundInfos[roundCounter] = roundProduct\n",
    "            else:\n",
    "                roundInfos[roundCounter].append(intermediatePool[idx][1][0])\n",
    "                \n",
    "        roundCounter += 1\n",
    "        scoreList.clear()\n",
    "    print(\"-- Finish Clustering --\")\n",
    "\n",
    "    return intermediatePool, initialDict, roundInfos, residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clusterInitializedReps(initializedReps_dict, tag, outputPath, thresholdValue):\n",
    "    intermediatePool = dict()\n",
    "    roundInfos = dict()\n",
    "    residual = None # used to save residual candidate when algorithm stop.\n",
    "#     toMergeCandidateDict = testDict\n",
    "    toMergeCandidateDict = initializedReps_dict # using residualRepsDict as toMergeCandidateDict (skip initialization)\n",
    "\n",
    "    # initialDict = {clusterName : (originalName, initialLength)}\n",
    "    initialDict = getInitialDict(toMergeCandidateDict)\n",
    "    \n",
    "    roundProduct = list()\n",
    "    for key, value in initialDict.items():\n",
    "        roundProduct.append(key)\n",
    "    roundInfos[0] = roundProduct # record product in round 0 (i.e., initialization)\n",
    "    \n",
    "    generatedSeqNum = len(toMergeCandidateDict) # counter after initialize. Used to naming clusters.\n",
    "\n",
    "    print(\"-- Start Clustering --\")\n",
    "    print(\"Threshold set =\", thresholdValue)\n",
    "    roundCounter = 1\n",
    "    \n",
    "    while(1):\n",
    "        print(\"Current Round : Round \", roundCounter)\n",
    "        if(len(toMergeCandidateDict) == 1):\n",
    "            residual = toMergeCandidateDict # output residual candidates.\n",
    "            break\n",
    "\n",
    "        # calculate scoreList in candidate clusters\n",
    "        scoreList = findMergeCandidateScoreList(toMergeCandidateDict, generatedSeqNum)\n",
    "        print(\"-- Finish scoring --\")\n",
    "        \n",
    "        # check and merge exactly the same candidates before merge clusters\n",
    "        scoreList = checkExactlySameCandidates(scoreList)\n",
    "        print(\"-- Finish checking 100% same candidates --\")\n",
    "        \n",
    "        # generated Clusters in This Round:\n",
    "        nameIdxStart = generatedSeqNum\n",
    "        \n",
    "        toMergeCandidateDict, intermediatePool, generatedSeqNum = mergeCandidateClusters_new(\n",
    "            toMergeCandidateDict, intermediatePool, scoreList, generatedSeqNum, initialDict, thresholdValue)\n",
    "        print(\"-- Finish merging clusters --\")\n",
    "        # check if algorithm should stop when merge score under threshold\n",
    "        # if a score smaller than threshold, then it will break out when merging.\n",
    "        # Hense, if the 'generatedSeqNum' equals than 'nameIdxStart', means that no any new generated cluster.\n",
    "        # (if occurr a new cluster, generatedSeqNum will add one.)\n",
    "        if(generatedSeqNum == nameIdxStart):\n",
    "            residual = toMergeCandidateDict # output residual candidates.\n",
    "            break # end algorithm\n",
    "        \n",
    "        nameIdxEnd = generatedSeqNum\n",
    "        \n",
    "        # Record clusters generated in this round\n",
    "        for idx in range(nameIdxStart, nameIdxEnd):\n",
    "            if roundInfos.get(roundCounter) is None:\n",
    "                roundProduct = list()\n",
    "                roundProduct.append(intermediatePool[idx][1][0])\n",
    "                roundInfos[roundCounter] = roundProduct\n",
    "            else:\n",
    "                roundInfos[roundCounter].append(intermediatePool[idx][1][0])\n",
    "                \n",
    "        roundCounter += 1\n",
    "        scoreList.clear()\n",
    "    print(\"-- Finish Clustering --\")\n",
    "\n",
    "    return intermediatePool, initialDict, roundInfos, residual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
