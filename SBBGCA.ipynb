{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A implementation of Sequence-Based Behavior Group Clustering Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shorten Name to first 6 charactors\n",
    "def shortenHooklogName(hkName):\n",
    "    hashValue = hkName[0:6]\n",
    "    pid = hkName.split(\"_\")[1].split(\".\")[0]\n",
    "    return hashValue+\"_\"+pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input: two R\n",
    "# output: new RepresentativeR of inputs;\n",
    "def get_Representative(Ri, Rj):\n",
    "    rep1 = list()\n",
    "    rep2 = list()\n",
    "\n",
    "    for i in range(len(Ri[1])): # get length of R's common motif seqs  (p.s. Ri[0] is clusterName)\n",
    "        rep1 += Ri[1][i][0]\n",
    "    for i in range(len(Rj[1])):\n",
    "        rep2 += Rj[1][i][0]\n",
    "    \n",
    "    comMotif_dict = do_globalAlignment(rep1, rep2) # do Alignment\n",
    "    \n",
    "    repNew = list() \n",
    "    newStartIdx = 0\n",
    "    \n",
    "    for m in sorted(comMotif_dict.keys(), key = lambda x : int(x.split('_')[0][1:])): # sorted by stages\n",
    "        cmsList = comMotif_dict[m]\n",
    "        newEndIdx = newStartIdx + len(cmsList[0]) - 1\n",
    "        repNew.append((cmsList[0], newStartIdx, newEndIdx, cmsList[1], cmsList[2]))\n",
    "                  # [CMS, newCMSStartIdx, newCMSEndIdx, oriIdxRange1, oriIdxRange2]\n",
    "        newStartIdx = newEndIdx + 1\n",
    "    \n",
    "    return repNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% run Alignment_Fast3.ipynb\n",
    "% run StructMatchGap3.ipynb\n",
    "% run StageMatrix.ipynb\n",
    "% run Motif.ipynb\n",
    "% run OutputStage.ipynb\n",
    "% run CommonMotifAnalysis_Tmp.ipynb\n",
    "\n",
    "# Doing global alignment and Calculate common motif.\n",
    "# will return a common motif dict\n",
    "def do_globalAlignment(rep1, rep2):\n",
    "    # Aligment\n",
    "    align_dict = dict()\n",
    "    BASE = \"rep1\"\n",
    "    align_dict['rep1'] = pairwise_NW( rep1, rep1, 2, -1, -3, 1)[2]\n",
    "    align_dict['rep2'] = pairwise_NW( rep1, rep2, 2, -1, -3, 1)[2]\n",
    "    \n",
    "    # get 'Match Matrix' and 'Gap List'\n",
    "    matchMatrix, gapSeqList = structMatchGap(align_dict, BASE)\n",
    "    stageMatrixResult = stageMatrix(matchMatrix, gapSeqList)\n",
    "    Motif_Obj = Motif(stageMatrixResult, BASE)\n",
    "    outputStage = OutputStage(stageMatrixResult, None, BASE, Motif_Obj)\n",
    "    \n",
    "    executionTrace_dict = {\"rep1\":rep1, \"rep2\":rep2}\n",
    "    \n",
    "    commonMotif = CommonMotif(stageMatrixResult, Motif_Obj, executionTrace_dict, outputStage)\n",
    "    \n",
    "    # comMotifdict= {'s<stage>_<motif>': [CMS], oriIdxRange1, oriIdxRange2},\n",
    "    comMotif_dict = commonMotif.getComMotifDict()  \n",
    "    return comMotif_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% run FeatureHooklog3.ipynb\n",
    "#******************** the output toMergeCandidate_Dict have to change to set\n",
    "\n",
    "# initialize all hooklogs as \"to merge candidates clusters\"\n",
    "def initialCandidateDict(data_directory):\n",
    "    \n",
    "#     toMergeCandidate_List = list()\n",
    "    toMergeCandidate_Dict = dict()\n",
    "    \n",
    "    # get feature hooklogs\n",
    "    Hooklog = FeatureHooklog3\n",
    "    hkName_list = list(filter(lambda f:f.endswith('.trace.hooklog'), os.listdir(data_directory))) # hooklog Name List\n",
    "    hk_count = 0\n",
    "    for hkName in hkName_list:\n",
    "        featureHooklog = Hooklog(data_directory + hkName, 1).getHkli_noContainTS()\n",
    "        clusterName = \"G\"+str(hk_count)\n",
    "        # R = tuple( clusterName, list(  tuple(featureHooklog, fhStartIdx, fhEndIdx) ) ), the representative of cluster.\n",
    "        R = (clusterName, [(featureHooklog, 0, len(featureHooklog)-1)] )\n",
    "        clusterMembers = set()\n",
    "        hkName = shortenHooklogName(hkName)\n",
    "        clusterMembers.add(hkName)\n",
    "        \n",
    "        toMergeCandidate_Dict[hk_count] = (R, clusterMembers)\n",
    "        \n",
    "        hk_count+=1\n",
    "        \n",
    "    print(\"-- Finish Initializing --\")\n",
    "    return toMergeCandidate_Dict\n",
    "#     return toMergeCandidateSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "# compute score of Rnew\n",
    "# the score calculate method is the length ratio of new to origin one\n",
    "def compute_Score(Ri, Rj, Rnew):\n",
    "    L_Ri = functools.reduce(lambda x,y:x+y, [len(i[0]) for i in Ri[1]])\n",
    "    L_Rj = functools.reduce(lambda x,y:x+y, [len(j[0]) for j in Rj[1]])\n",
    "    \n",
    "    Lorg = max(L_Ri, L_Rj)\n",
    "    Lnew = functools.reduce(lambda x,y:x+y, [len(n[0]) for n in Rnew[1]]) \n",
    "    score = float(Lnew)/Lorg\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get score list of toMergeCandidateDict(single iteration) from highest to lowest\n",
    "\n",
    "def findMergeCandidateScoreList(toMergeCandidateDict, iterateCounter):\n",
    "    scoreList = list()\n",
    "    dictKeys = list(toMergeCandidateDict.keys())\n",
    "    \n",
    "    for i in range(len(dictKeys)):\n",
    "        for j in range(i+1, len(dictKeys)):\n",
    "            \n",
    "            # toMergeCandidateDict[i][1] is memberSet\n",
    "            Ri = toMergeCandidateDict[ dictKeys[i] ][0] # Ri is a tuple like (('G0', [[['A#A', 'C#C'], 0, 1, (0, 1), (1, 2)]]))\n",
    "            Rj = toMergeCandidateDict[ dictKeys[j] ][0]\n",
    "            \n",
    "            # create Rnew = (clusterName , repNew)\n",
    "            repNew = get_Representative(Ri, Rj)\n",
    "            clusterTempName = \"G\" + str(iterateCounter)\n",
    "            Rnew = (clusterTempName , repNew)\n",
    "            \n",
    "            # compute merge score of Rnew\n",
    "            score = compute_Score(Ri, Rj, Rnew)\n",
    "            \n",
    "            Ri_name = Ri[0]\n",
    "            Rj_name = Rj[0]\n",
    "            \n",
    "            scoreList.append((score, Rnew, Ri_name, Rj_name))\n",
    "            \n",
    "    if(len(scoreList) > 0):\n",
    "        scoreList.sort(key=lambda tup:tup[0], reverse=True) # sorting by score (from biggest to smallest) \n",
    "    else:\n",
    "        print(\"No common motif\")\n",
    "    \n",
    "#     memlist = [(s[2], s[3]) for s in scoreList]\n",
    "#     print(\"member pairs in scoreList : iterate: \", iterateCounter,\"\\n\", memlist)\n",
    "    return scoreList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add Rnew into toMergeCandidateDict and remove member of Rnew from candidates.\n",
    "\n",
    "def mergeCandidateClusters(toMergeCandidateDict, intermediatePoolDict, scoreList, iterateCounter, initialNames):\n",
    "    currentMergedSet = set()\n",
    "        \n",
    "    for rank in scoreList:\n",
    "        Ri_name = rank[2] # member1 of highest score\n",
    "        Rj_name = rank[3] # member2 of highest score\n",
    "\n",
    "        # check exclusiveness that candidate have been merged in current scoreList.\n",
    "        if((Ri_name not in currentMergedSet) and (Rj_name not in currentMergedSet)):\n",
    "            # remove candidates in @toMergeCandidateDict\n",
    "            keyOfRi = int(Ri_name.split('G')[1])\n",
    "            keyOfRj = int(Rj_name.split('G')[1])\n",
    "            del toMergeCandidateDict[keyOfRi], toMergeCandidateDict[keyOfRj]\n",
    "\n",
    "            Rnew = rank[1] # get representative of highest score\n",
    "            newName = \"G\" + str(iterateCounter) # update clusterName\n",
    "        \n",
    "            new_Cluster = (newName, Rnew[1])\n",
    "\n",
    "            clusterMembers = set() # create cluster member set\n",
    "            if Ri_name in initialNames:\n",
    "                clusterMembers.add(initialNames[Ri_name])\n",
    "            else:\n",
    "                clusterMembers.add(Ri_name)\n",
    "            \n",
    "            \n",
    "            if Rj_name in initialNames:\n",
    "                clusterMembers.add(initialNames[Rj_name])\n",
    "            else:\n",
    "                clusterMembers.add(Rj_name)\n",
    "            \n",
    "            \n",
    "            toMergeCandidateDict[iterateCounter] = (new_Cluster, clusterMembers)\n",
    "            intermediatePoolDict[iterateCounter] = (rank[0], new_Cluster, clusterMembers) # (score, newCluster, members)\n",
    "\n",
    "            iterateCounter += 1\n",
    "\n",
    "            currentMergedSet.add(Ri_name) # update currentMergedSet\n",
    "            currentMergedSet.add(Rj_name)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return toMergeCandidateDict, intermediatePoolDict, iterateCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Main Function of SBBGCA ###\n",
    "\n",
    "import pickle\n",
    "\n",
    "def do_SBBGCA_clustering(data_directory, tag, outputPath):\n",
    "    # testDict = {0: (('G0', [[['A#A', 'B#B','B#B', 'C#C','D#D'], 0, 2]]),{\"a.trace.hooklog\"}), 1:(('G1', [[['A#A','C#C','D#D'], 0, 2]]),{\"b.trace.hooklog\"})}\n",
    "\n",
    "    intermediatePool = dict()\n",
    "\n",
    "    toMergeCandidateDict = initialCandidateDict(data_directory) # initialize @toMergeCandidateDict\n",
    "\n",
    "    # initialNames = {value[0][0]: value[1].pop() for key, value in toMergeCandidateDict}\n",
    "    initialNames = dict()\n",
    "    for key, value in toMergeCandidateDict.items():\n",
    "        clusterName = value[0][0]\n",
    "        originalName = value[1].pop()\n",
    "        initialNames[clusterName] = originalName\n",
    "\n",
    "    iterateCounter = len(toMergeCandidateDict) # counter after initialize. Used to naming clusters.\n",
    "\n",
    "    print(\"-- Start Clustering --\")\n",
    "    while(1):\n",
    "        if(len(toMergeCandidateDict) == 1):\n",
    "            break\n",
    "\n",
    "        # calculate scoreList in candidate clusters\n",
    "        scoreList = findMergeCandidateScoreList(toMergeCandidateDict, iterateCounter)\n",
    "        if(len(scoreList) == 0):\n",
    "            break\n",
    "        toMergeCandidateDict, intermediatePool, iterateCounter = mergeCandidateClusters(toMergeCandidateDict, intermediatePool, scoreList, iterateCounter, initialNames)\n",
    "\n",
    "    print(\"-- Finish Clustering --\")\n",
    "\n",
    "    return intermediatePool, initialNames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
